{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "\n",
      "with open('creative_commons.txt', 'r') as f:\n",
      "    html = f.read()\n",
      "    \n",
      "with open('./styles/custom.css', 'r') as f:\n",
      "    styles = f.read()\n",
      "    \n",
      "HTML(styles)\n",
      "\n",
      "name = 'download_hdf'\n",
      "\n",
      "html = \"\"\"\n",
      "<small>\n",
      "<p> This post was written as an IPython notebook. It is available for <a href=\"http://ocef\n",
      "paf.github.com/downloads/notebooks/%s.ipynb\">download</a> or as a static <a href=\"http://\n",
      "nbviewer.ipython.org/url/ocefpaf.github.com/downloads/notebooks/%s.ipynb\">html</a>.</p>\n",
      "<p></p>\n",
      "%s \"\"\" % (name, name, html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<!-- PELICAN_BEGIN_SUMMARY -->\n",
      "This post is a quick example on how to use download several\n",
      "[hdf 4 files](http://oceandata.sci.gsfc.nasa.gov/CZCS/Mapped/Monthly/4km/chlor/)\n",
      "by \"scrapping\" NASA's server.\n",
      "<!-- PELICAN_END_SUMMARY -->"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manually downloading several `hdf` files is, most of the time, impractical.\n",
      "Some time ago I helped a friend with a similar problem with a simple python\n",
      "script.  This post is just a review of that script so others can modify/re-use\n",
      "it for similar cases."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All we need is a `lister` class to extract the `urls` from the web-page, and a\n",
      "`hook` function to show the download progress progress."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import urllib\n",
      "import fnmatch\n",
      "from sgmllib import SGMLParser\n",
      "\n",
      "\n",
      "class URLLister(SGMLParser):\n",
      "    \"\"\"Get urls from a html dump.\n",
      "    http://stackoverflow.com/questions/9450571/\n",
      "    how-to-extract-specified-text-in-html-using-sgmlparser.\"\"\"\n",
      "    def reset(self):\n",
      "        SGMLParser.reset(self)\n",
      "        self.urls = []\n",
      "\n",
      "    def start_a(self, attrs):\n",
      "        href = [v for k, v in attrs if k == 'href']\n",
      "        if href:\n",
      "            self.urls.extend(href)\n",
      "\n",
      "\n",
      "def progress_hook(out):\n",
      "    \"\"\"Return a progress hook function, suitable for passing to\n",
      "    urllib.retrieve, that writes to the file object *out*.\"\"\"\n",
      "    def it(n, bs, ts):\n",
      "        got = n * bs\n",
      "        if ts < 0:\n",
      "            outof = ''\n",
      "        else:\n",
      "            # On the last block n*bs can exceed ts, so we clamp it\n",
      "            # to avoid awkward questions.\n",
      "            got = min(got, ts)\n",
      "            outof = '/%d [%d%%]' % (ts, 100 * got // ts)\n",
      "        out.write(\"\\r  %d%s\" % (got, outof))\n",
      "        out.flush()\n",
      "    return it"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we will download the\n",
      "[Mapped Monthly mean 4km CZCS data](http://oceandata.sci.gsfc.nasa.gov/CZCS/Mapped/Monthly/4km/chlor/),\n",
      "but this script can be extended to any web-page that has a list of urls."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = \"http://oceandata.sci.gsfc.nasa.gov/CZCS/Mapped/Monthly/4km/chlor/\"\n",
      "\n",
      "# Get page html and parse urls.\n",
      "usock = urllib.urlopen(url)\n",
      "parser = URLLister()\n",
      "parser.feed(usock.read())\n",
      "usock.close()\n",
      "parser.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before downloading let's filter by the filename extension (bz2), so we download just\n",
      "what we really want."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filetype = \"*.bz2\"\n",
      "file_list = [filename for filename in fnmatch.filter(parser.urls, filetype)]\n",
      "\n",
      "for url in file_list:\n",
      "    hdf_file = url.split('/')[-1]\n",
      "    sys.stdout.write(hdf_file + '\\n')\n",
      "    urllib.urlretrieve(url, filename=hdf_file,\n",
      "                       reporthook=progress_hook(sys.stdout))\n",
      "    sys.stdout.write('\\n')\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "<small>\n",
        "<p> This post was written as an IPython notebook. It is available for <a href=\"http://ocef\n",
        "paf.github.com/downloads/notebooks/download_hdf.ipynb\">download</a> or as a static <a href=\"http://\n",
        "nbviewer.ipython.org/url/ocefpaf.github.com/downloads/notebooks/download_hdf.ipynb\">html</a>.</p>\n",
        "<p></p>\n",
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img\n",
        "alt=\"Creative Commons License\" style=\"border-width:0\"\n",
        "src=\"http://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br /><span\n",
        "xmlns:dct=\"http://purl.org/dc/terms/\"\n",
        "property=\"dct:title\">python4oceanographers</span> by <a\n",
        "xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://ocefpaf.github.io/\"\n",
        "property=\"cc:attributionName\" rel=\"cc:attributionURL\">Filipe Fernandes</a> is\n",
        "licensed under a <a rel=\"license\"\n",
        "href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons\n",
        "Attribution-ShareAlike 4.0 International License</a>.<br />Based on a work at <a\n",
        "xmlns:dct=\"http://purl.org/dc/terms/\" href=\"http://ocefpaf.github.io/\"\n",
        "rel=\"dct:source\">http://ocefpaf.github.io/</a>.\n",
        " "
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<IPython.core.display.HTML at 0x24f29d0>"
       ]
      }
     ],
     "prompt_number": 2
    }
   ],
   "metadata": {}
  }
 ]
}